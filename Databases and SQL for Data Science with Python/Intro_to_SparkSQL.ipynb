{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PdI6wLpCJ1iM"
      },
      "outputs": [],
      "source": [
        "!pip install pyspark\n",
        "!pip install findspark\n",
        "!pip install pyarrow==0.14.1\n",
        "!pip install pandas\n",
        "!pip install numpy==1.19.5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "8_W-2-YuJ3lJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "iE0pHGbhJ5Dd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc = SparkContext()\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Python Spark DataFrames basic example\") \\\n",
        "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "IriBk_p7J64A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mtcars = pd.read_csv('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0225EN-SkillsNetwork/labs/data/mtcars.csv')"
      ],
      "metadata": {
        "id": "6_Vl6zXjKDz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mtcars.rename( columns={'Unnamed: 0':'name'}, inplace=True )"
      ],
      "metadata": {
        "id": "Wp7xRQwCKF2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sdf = spark.createDataFrame(mtcars)"
      ],
      "metadata": {
        "id": "3Ot3HrHJKHo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sdf.printSchema()"
      ],
      "metadata": {
        "id": "q2SU7eGcKJUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sdf_new = sdf.withColumnRenamed(\"vs\", \"versus\")"
      ],
      "metadata": {
        "id": "FNFFtL0MKLSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sdf_new.head(5)"
      ],
      "metadata": {
        "id": "a3I61kZxKMuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sdf.createTempView(\"cars\")"
      ],
      "metadata": {
        "id": "473q7E_mKOrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"SELECT * FROM cars\").show()"
      ],
      "metadata": {
        "id": "JuhPy5grKQjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"SELECT mpg FROM cars\").show(5)"
      ],
      "metadata": {
        "id": "v6BXSe2zKS45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"SELECT * FROM cars where mpg>20 AND cyl < 6\").show(5)"
      ],
      "metadata": {
        "id": "edJFsz8HKUNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sdf.where(sdf['mpg'] < 18).show(3)"
      ],
      "metadata": {
        "id": "N3GLOwwhKVnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"SELECT count(*), cyl from cars GROUP BY cyl\").show()"
      ],
      "metadata": {
        "id": "QaufuPZ3KW3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import pandas_udf, PandasUDFType"
      ],
      "metadata": {
        "id": "01rJtYvPKZSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@pandas_udf(\"float\")\n",
        "def convert_wt(s: pd.Series) -> pd.Series:\n",
        "    # The formula for converting from imperial to metric tons\n",
        "    return s * 0.45\n",
        "\n",
        "spark.udf.register(\"convert_weight\", convert_wt)"
      ],
      "metadata": {
        "id": "1W8_-3kwKa4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"SELECT *, wt AS weight_imperial, convert_weight(wt) as weight_metric FROM cars\").show()"
      ],
      "metadata": {
        "id": "_1d93FYeKcqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [(\"A101\", \"John\"), (\"A102\", \"Peter\"), (\"A103\", \"Charlie\")]\n",
        "\n",
        "columns = [\"emp_id\", \"emp_name\"]\n",
        "\n",
        "dataframe_1 = spark.createDataFrame(data, columns)"
      ],
      "metadata": {
        "id": "cD0Gr06kKeU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [(\"A101\", 3250), (\"A102\", 6735), (\"A103\", 8650)]\n",
        "\n",
        "columns = [\"emp_id\", \"salary\"]\n",
        "\n",
        "dataframe_2 = spark.createDataFrame(data, columns)"
      ],
      "metadata": {
        "id": "cHQrrVXlKgNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df = dataframe_1.join(dataframe_2, on=\"emp_id\", how=\"inner\")"
      ],
      "metadata": {
        "id": "fMEBUSRzKiN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df.collect()"
      ],
      "metadata": {
        "id": "nvT0OOL0KkIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [(\"A101\", 1000), (\"A102\", 2000), (\"A103\",None)]\n",
        "\n",
        "columns = [\"emp_id\", \"salary\"]\n",
        "\n",
        "dataframe_1 = spark.createDataFrame(data, columns)"
      ],
      "metadata": {
        "id": "JNzyQTNJKmLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filled_df = dataframe_1.fillna({\"salary\": 3000})"
      ],
      "metadata": {
        "id": "i4P18hDIKpqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"SELECT * FROM cars where name like 'Merc%'\").show()\n"
      ],
      "metadata": {
        "id": "Ywyoq9QUKsVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import pandas_udf\n",
        "\n",
        "@pandas_udf(\"float\")\n",
        "def convert_mileage(s: pd.Series) -> pd.Series:\n",
        "    return s * 0.425\n",
        "\n",
        "spark.udf.register(\"convert_mileage\", convert_mileage)\n",
        "\n",
        "spark.sql(\"SELECT *, mpg AS mpg, convert_mileage(mpg) as kmpl FROM cars\").show()"
      ],
      "metadata": {
        "id": "9uQhh_sdKvY4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}